# Prueba T√©cnica ‚Äì ETL con Airflow

## Descripci√≥n
Este proyecto refactoriza una Lambda en un pipeline ETL con tres etapas orquestadas en **Apache Airflow**:
1. **Extracci√≥n:** obtiene datos mediante scraping.
2. **Validaci√≥n:** limpia y valida los datos seg√∫n reglas configurables.
3. **Escritura:** inserta los datos en una base de datos PostgreSQL.

El objetivo es mantener la l√≥gica original del scraping, agregar validaci√≥n configurable e implementar idempotencia b√°sica (evitar duplicados).

---


## Levantar el entorno

### Requisitos
- Docker y Docker Compose instalados.
- GNU Make instalado (`choco install make` en Windows o `brew install make` en macOS).

---

### üß© Archivo `.env`

Crea un archivo llamado `.env` en la **ra√≠z del proyecto** con las variables necesarias para ejecutar el proyecto.

Ejemplo:

```bash
# Variables de entorno
PYTHONPATH=/opt/airflow/src
```

### Instalaci√≥n completa
```bash
make install
```
Esto:
1. Detiene cualquier contenedor anterior.
2. Reconstruye las im√°genes.
3. Inicializa Airflow y crea el usuario `admin / admin`.


---

### Acceso
- Interfaz de Airflow: [http://localhost:8080](http://localhost:8080)  
  Usuario: `admin`  
  Contrase√±a: `admin`

---

### Ejecuci√≥n del DAG
1. En la interfaz de Airflow, activa el DAG `dapper_pipeline`.
2. Haz clic en **Trigger DAG** para ejecutarlo.
3. Observa los logs de cada tarea (extract, validate, write).

---


## Logs y resultados
Los logs se almacenan en `./logs/` e incluyen:
- Total de registros extra√≠dos.
- Filas descartadas por validaci√≥n.
- Filas insertadas en base de datos.

---

## Reglas de validaci√≥n (`rules.json`)
El archivo `src/validation/rules.json` define las reglas que se aplican a cada campo del DataFrame antes de insertarlo.

Ejemplo:
```json
{
  "title": {
    "type": "string",
    "regex": "^[A-Z√Å√â√ç√ì√ö√ë0-9\\s\\-_,.]+$",
    "required": true
  },
  "created_at": {
    "type": "date",
    "regex": "^\\d{4}-\\d{2}-\\d{2}$",
    "required": true
  },
  "external_link": {
    "type": "string",
    "regex": "^https?://",
    "required": true
  },
  "summary": {
    "type": "string",
    "regex": ".*",
    "required": false
  }
}
```

### C√≥mo funciona
- Si un campo **obligatorio (`required: true`)** no cumple su tipo o regex, la fila se **descarta**.
- Si un campo **no obligatorio** no cumple, el valor se reemplaza por `NULL`.
- Las reglas pueden modificarse sin cambiar el c√≥digo: basta con editar `rules.json`.

---


### Deshabilitar el sistema:
```bash
make down-airflow
```
---
Nota: La proxima vez que se vaya a utilizar el sistema, es recomendable usar el siguiente comando:
### Levantar sin reconstruir
```bash
make up-airflow
```

## Estructura principal
```
/dags
 ‚îî‚îÄ‚îÄ dapper_pipeline_dag.py     # DAG principal de Airflow
/src
 ‚îú‚îÄ‚îÄ extraction/scraper.py      # M√≥dulo de extracci√≥n
 ‚îú‚îÄ‚îÄ validation/validator.py    # M√≥dulo de validaci√≥n
 ‚îú‚îÄ‚îÄ validation/rules.json      # Reglas configurables de validaci√≥n
 ‚îî‚îÄ‚îÄ persistence/writer.py      # M√≥dulo de escritura
/configs
 ‚îî‚îÄ‚îÄ schema.sql                 # Esquema base de la tabla destino
```

---

## Comandos Make disponibles
| Comando | Descripci√≥n |
|----------|--------------|
| `make install` | Instala, construye e inicializa Airflow. |
| `make up-airflow` | Levanta el entorno sin reconstruir. |
| `make init-airflow` | Inicializa Airflow y crea usuario admin. |
| `make down-airflow` | Detiene y elimina los contenedores. |
| `make build-airflow` | Reconstruye las im√°genes y levanta los servicios. |

---

## Contacto
Proyecto desarrollado como parte de una prueba t√©cnica para Dapper.

Eder Hern√°ndez Buelvas
ederhernandez667@gmail.com
